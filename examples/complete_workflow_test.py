"""
å®Œæ•´çš„å·¥ä½œæµç«¯åˆ°ç«¯æµ‹è¯•

æµ‹è¯•å®Œæ•´çš„Text2SQLå·¥ä½œæµï¼ŒåŒ…æ‹¬æ‰€æœ‰æ™ºèƒ½ä½“çš„çœŸå®åä½œã€‚
ä½¿ç”¨MySQLæ•°æ®åº“è¿›è¡ŒçœŸå®çš„ç«¯åˆ°ç«¯æµ‹è¯•ã€‚
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.workflow import OptimizedChatManager
from config.settings import config
import logging
import json
import pymysql

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def setup_mysql_test_data():
    """è®¾ç½®MySQLæµ‹è¯•æ•°æ®"""
    logger.info("è®¾ç½®MySQLæµ‹è¯•æ•°æ®...")
    
    # è¿æ¥åˆ°MySQLæ•°æ®åº“
    connection = pymysql.connect(
        host=config.database_config.host,
        port=config.database_config.port,
        user=config.database_config.username,
        password=config.database_config.password,
        database=config.database_config.database,
        charset='utf8mb4'
    )
    
    try:
        cursor = connection.cursor()
        
        # åˆ›å»ºå­¦æ ¡æµ‹è¯•è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS schools (
                school_id INT AUTO_INCREMENT PRIMARY KEY,
                school_name VARCHAR(200) NOT NULL,
                district_id INT,
                city VARCHAR(100),
                sat_score INT,
                enrollment INT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS districts (
                district_id INT AUTO_INCREMENT PRIMARY KEY,
                district_name VARCHAR(200) NOT NULL,
                city VARCHAR(100),
                county VARCHAR(100),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """)
        
        # æ¸…ç†ç°æœ‰æµ‹è¯•æ•°æ®
        cursor.execute("DELETE FROM schools WHERE school_name LIKE '%Test%' OR city IN ('Los Angeles', 'San Francisco', 'San Diego')")
        cursor.execute("DELETE FROM districts WHERE district_name LIKE '%Test%' OR city IN ('Los Angeles', 'San Francisco', 'San Diego')")
        
        # æ’å…¥æµ‹è¯•æ•°æ®
        districts_data = [
            ("Los Angeles Unified Test", "Los Angeles", "Los Angeles County"),
            ("San Francisco Unified Test", "San Francisco", "San Francisco County"),
            ("San Diego Unified Test", "San Diego", "San Diego County")
        ]
        
        cursor.executemany(
            "INSERT INTO districts (district_name, city, county) VALUES (%s, %s, %s)",
            districts_data
        )
        
        # è·å–æ’å…¥çš„district_id
        cursor.execute("SELECT district_id, city FROM districts WHERE district_name LIKE '%Test%' ORDER BY district_id")
        district_mapping = {city: district_id for district_id, city in cursor.fetchall()}
        
        schools_data = [
            ("Lincoln High School Test", district_mapping["Los Angeles"], "Los Angeles", 1450, 2500),
            ("Washington High School Test", district_mapping["Los Angeles"], "Los Angeles", 1380, 2200),
            ("Roosevelt High School Test", district_mapping["San Francisco"], "San Francisco", 1520, 1800),
            ("Jefferson High School Test", district_mapping["San Francisco"], "San Francisco", 1420, 1900),
            ("Madison High School Test", district_mapping["San Diego"], "San Diego", 1480, 2100),
            ("Monroe High School Test", district_mapping["San Diego"], "San Diego", 1350, 1950)
        ]
        
        cursor.executemany(
            "INSERT INTO schools (school_name, district_id, city, sat_score, enrollment) VALUES (%s, %s, %s, %s, %s)",
            schools_data
        )
        
        connection.commit()
        
        # éªŒè¯æ•°æ®æ’å…¥
        cursor.execute("SELECT COUNT(*) FROM schools WHERE school_name LIKE '%Test%'")
        school_count = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM districts WHERE district_name LIKE '%Test%'")
        district_count = cursor.fetchone()[0]
        
        logger.info(f"æµ‹è¯•æ•°æ®æ’å…¥æˆåŠŸ: {school_count} æ‰€å­¦æ ¡, {district_count} ä¸ªå­¦åŒº")
        
        return True
        
    except Exception as e:
        logger.error(f"è®¾ç½®æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
        connection.rollback()
        return False
    finally:
        cursor.close()
        connection.close()


def cleanup_mysql_test_data():
    """æ¸…ç†MySQLæµ‹è¯•æ•°æ®"""
    logger.info("æ¸…ç†MySQLæµ‹è¯•æ•°æ®...")
    
    try:
        connection = pymysql.connect(
            host=config.database_config.host,
            port=config.database_config.port,
            user=config.database_config.username,
            password=config.database_config.password,
            database=config.database_config.database,
            charset='utf8mb4'
        )
        
        cursor = connection.cursor()
        
        # åˆ é™¤æµ‹è¯•æ•°æ®
        cursor.execute("DELETE FROM schools WHERE school_name LIKE '%Test%'")
        cursor.execute("DELETE FROM districts WHERE district_name LIKE '%Test%'")
        
        connection.commit()
        logger.info("æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
        
    except Exception as e:
        logger.error(f"æ¸…ç†æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'connection' in locals():
            connection.close()


def test_simple_query():
    """æµ‹è¯•ç®€å•æŸ¥è¯¢"""
    logger.info("=== æµ‹è¯•ç®€å•æŸ¥è¯¢ ===")
    
    # åˆ›å»ºChatManagerï¼Œä½¿ç”¨é»˜è®¤é…ç½®è¿æ¥MySQL
    chat_manager = OptimizedChatManager(
        data_path="data",
        tables_json_path="data/tables.json",
        dataset_name="bird",
        max_rounds=3
    )
    
    # æµ‹è¯•æŸ¥è¯¢
    result = chat_manager.process_query(
        db_id="text2sql_db",  # ä½¿ç”¨å®é™…çš„MySQLæ•°æ®åº“å
        query="List all schools in Los Angeles",
        evidence="The schools table contains school information including city"
    )
    
    # è¾“å‡ºç»“æœ
    logger.info(f"æŸ¥è¯¢ç»“æœ:")
    logger.info(f"  æˆåŠŸ: {result['success']}")
    logger.info(f"  SQL: {result.get('sql', 'N/A')}")
    logger.info(f"  å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f}ç§’")
    logger.info(f"  é‡è¯•æ¬¡æ•°: {result.get('retry_count', 0)}")
    
    if result['success']:
        exec_result = result.get('execution_result', {})
        if exec_result.get('data'):
            logger.info(f"  æŸ¥è¯¢ç»“æœè¡Œæ•°: {len(exec_result['data'])}")
            logger.info(f"  å‰3è¡Œæ•°æ®: {exec_result['data'][:3]}")
        
        # æ˜¾ç¤ºæ™ºèƒ½ä½“æ‰§è¡Œæ—¶é—´
        agent_times = result.get('agent_execution_times', {})
        if agent_times:
            logger.info("  æ™ºèƒ½ä½“æ‰§è¡Œæ—¶é—´:")
            for agent, time_spent in agent_times.items():
                logger.info(f"    {agent}: {time_spent:.2f}ç§’")
    else:
        logger.error(f"  é”™è¯¯: {result.get('error', 'Unknown error')}")
        logger.error(f"  å¤±è´¥çš„SQL: {result.get('failed_sql', 'N/A')}")
        logger.error(f"  å¤„ç†é˜¶æ®µ: {result.get('processing_stage', 'N/A')}")
    
    return result


def test_complex_query():
    """æµ‹è¯•å¤æ‚æŸ¥è¯¢"""
    logger.info("=== æµ‹è¯•å¤æ‚æŸ¥è¯¢ ===")
    
    # åˆ›å»ºChatManager
    chat_manager = OptimizedChatManager(
        data_path="data",
        tables_json_path="data/tables.json",
        dataset_name="bird",
        max_rounds=3
    )
    
    # æµ‹è¯•å¤æ‚æŸ¥è¯¢
    result = chat_manager.process_query(
        db_id="text2sql_db",
        query="Show me schools with SAT scores above 1400 and their district information",
        evidence="Need to join schools and districts tables to get complete information"
    )
    
    # è¾“å‡ºç»“æœ
    logger.info(f"å¤æ‚æŸ¥è¯¢ç»“æœ:")
    logger.info(f"  æˆåŠŸ: {result['success']}")
    logger.info(f"  SQL: {result.get('sql', 'N/A')}")
    logger.info(f"  å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f}ç§’")
    logger.info(f"  é‡è¯•æ¬¡æ•°: {result.get('retry_count', 0)}")
    logger.info(f"  æ¨¡å¼è£å‰ª: {result.get('schema_pruned', False)}")
    logger.info(f"  åˆ†è§£ç­–ç•¥: {result.get('decomposition_strategy', 'N/A')}")
    
    if result['success']:
        exec_result = result.get('execution_result', {})
        if exec_result.get('data'):
            logger.info(f"  æŸ¥è¯¢ç»“æœè¡Œæ•°: {len(exec_result['data'])}")
            logger.info(f"  å‰3è¡Œæ•°æ®: {exec_result['data'][:3]}")
    else:
        logger.error(f"  é”™è¯¯: {result.get('error', 'Unknown error')}")
    
    return result


def test_aggregation_query():
    """æµ‹è¯•èšåˆæŸ¥è¯¢"""
    logger.info("=== æµ‹è¯•èšåˆæŸ¥è¯¢ ===")
    
    # åˆ›å»ºChatManager
    chat_manager = OptimizedChatManager(
        data_path="data",
        tables_json_path="data/tables.json",
        dataset_name="bird",
        max_rounds=3
    )
    
    # æµ‹è¯•èšåˆæŸ¥è¯¢
    result = chat_manager.process_query(
        db_id="text2sql_db",
        query="What is the average SAT score by city?",
        evidence="Need to calculate average SAT scores grouped by city"
    )
    
    # è¾“å‡ºç»“æœ
    logger.info(f"èšåˆæŸ¥è¯¢ç»“æœ:")
    logger.info(f"  æˆåŠŸ: {result['success']}")
    logger.info(f"  SQL: {result.get('sql', 'N/A')}")
    logger.info(f"  å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f}ç§’")
    logger.info(f"  é‡è¯•æ¬¡æ•°: {result.get('retry_count', 0)}")
    
    if result['success']:
        exec_result = result.get('execution_result', {})
        if exec_result.get('data'):
            logger.info(f"  æŸ¥è¯¢ç»“æœè¡Œæ•°: {len(exec_result['data'])}")
            logger.info(f"  èšåˆç»“æœ: {exec_result['data']}")
    else:
        logger.error(f"  é”™è¯¯: {result.get('error', 'Unknown error')}")
    
    return result


def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    logger.info("=== æµ‹è¯•é”™è¯¯å¤„ç† ===")
    
    # åˆ›å»ºChatManager
    chat_manager = OptimizedChatManager(
        data_path="data",
        tables_json_path="data/tables.json",
        dataset_name="bird",
        max_rounds=2  # å‡å°‘é‡è¯•æ¬¡æ•°ä»¥å¿«é€Ÿæµ‹è¯•
    )
    
    # æµ‹è¯•å¯èƒ½å¯¼è‡´é”™è¯¯çš„æŸ¥è¯¢
    result = chat_manager.process_query(
        db_id="text2sql_db",
        query="Show me information from the nonexistent_table",
        evidence="This query should fail because the table doesn't exist"
    )
    
    # è¾“å‡ºç»“æœ
    logger.info(f"é”™è¯¯å¤„ç†æµ‹è¯•ç»“æœ:")
    logger.info(f"  æˆåŠŸ: {result['success']}")
    logger.info(f"  SQL: {result.get('sql', 'N/A')}")
    logger.info(f"  å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f}ç§’")
    logger.info(f"  é‡è¯•æ¬¡æ•°: {result.get('retry_count', 0)}")
    
    if not result['success']:
        logger.info(f"  é”™è¯¯ä¿¡æ¯: {result.get('error', 'Unknown error')}")
        logger.info(f"  å¤±è´¥çš„SQL: {result.get('failed_sql', 'N/A')}")
        logger.info(f"  å¤„ç†é˜¶æ®µ: {result.get('processing_stage', 'N/A')}")
    
    return result


def test_workflow_statistics():
    """æµ‹è¯•å·¥ä½œæµç»Ÿè®¡åŠŸèƒ½"""
    logger.info("=== æµ‹è¯•å·¥ä½œæµç»Ÿè®¡åŠŸèƒ½ ===")
    
    # åˆ›å»ºChatManager
    chat_manager = OptimizedChatManager(
        data_path="data",
        tables_json_path="data/tables.json",
        dataset_name="bird",
        max_rounds=3
    )
    
    # æ‰§è¡Œå¤šä¸ªæŸ¥è¯¢
    queries = [
        ("List all users", "Simple query test"),
        ("Show products with price > 100", "Filter query test"),
        ("Average price by category", "Aggregation query test"),
        ("Invalid query with wrong table", "Error test")
    ]
    
    results = []
    for query, evidence in queries:
        logger.info(f"æ‰§è¡ŒæŸ¥è¯¢: {query}")
        result = chat_manager.process_query(
            db_id="text2sql_db",
            query=query,
            evidence=evidence
        )
        results.append(result)
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = chat_manager.get_stats()
    logger.info(f"å·¥ä½œæµç»Ÿè®¡ä¿¡æ¯:")
    logger.info(f"  æ€»æŸ¥è¯¢æ•°: {stats['total_queries']}")
    logger.info(f"  æˆåŠŸæŸ¥è¯¢æ•°: {stats['successful_queries']}")
    logger.info(f"  å¤±è´¥æŸ¥è¯¢æ•°: {stats['failed_queries']}")
    logger.info(f"  æˆåŠŸç‡: {stats['successful_queries']/stats['total_queries']*100:.1f}%")
    logger.info(f"  å¹³å‡å¤„ç†æ—¶é—´: {stats['average_processing_time']:.2f}ç§’")
    logger.info(f"  é‡è¯•ç‡: {stats['retry_rate']*100:.1f}%")
    
    # å¥åº·æ£€æŸ¥
    health = chat_manager.health_check()
    logger.info(f"ç³»ç»Ÿå¥åº·çŠ¶æ€: {health['status']}")
    
    return results, stats


def test_concurrent_queries():
    """æµ‹è¯•å¹¶å‘æŸ¥è¯¢å¤„ç†"""
    logger.info("=== æµ‹è¯•å¹¶å‘æŸ¥è¯¢å¤„ç† ===")
    
    import threading
    import queue
    
    # åˆ›å»ºChatManager
    chat_manager = OptimizedChatManager(
        data_path="data",
        tables_json_path="data/tables.json",
        dataset_name="bird",
        max_rounds=3
    )
    
    # å¹¶å‘æŸ¥è¯¢
    queries = [
        "List all users",
        "Show products with price above 100",
        "What is the average order amount?",
        "List all categories",
        "Show recent orders"
    ]
    
    results_queue = queue.Queue()
    
    def execute_query(query_id, query):
        try:
            result = chat_manager.process_query(
                db_id="text2sql_db",
                query=query,
                evidence=f"Concurrent test query {query_id}"
            )
            results_queue.put((query_id, query, result))
        except Exception as e:
            results_queue.put((query_id, query, {"error": str(e), "success": False}))
    
    # å¯åŠ¨å¹¶å‘çº¿ç¨‹
    threads = []
    for i, query in enumerate(queries):
        thread = threading.Thread(target=execute_query, args=(i, query))
        threads.append(thread)
        thread.start()
    
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for thread in threads:
        thread.join(timeout=60)  # 60ç§’è¶…æ—¶
    
    # æ”¶é›†ç»“æœ
    results = []
    while not results_queue.empty():
        results.append(results_queue.get())
    
    # è¾“å‡ºç»“æœ
    logger.info(f"å¹¶å‘æŸ¥è¯¢ç»“æœ:")
    for query_id, query, result in results:
        logger.info(f"  æŸ¥è¯¢ {query_id}: {result['success']} - {query[:30]}...")
    
    # æœ€ç»ˆç»Ÿè®¡
    stats = chat_manager.get_stats()
    logger.info(f"å¹¶å‘æµ‹è¯•ç»Ÿè®¡:")
    logger.info(f"  æ€»æŸ¥è¯¢æ•°: {stats['total_queries']}")
    logger.info(f"  æˆåŠŸæŸ¥è¯¢æ•°: {stats['successful_queries']}")
    logger.info(f"  å¹³å‡å¤„ç†æ—¶é—´: {stats['average_processing_time']:.2f}ç§’")
    
    return results


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹å®Œæ•´çš„å·¥ä½œæµç«¯åˆ°ç«¯æµ‹è¯•")
    logger.info(f"æ•°æ®åº“é…ç½®: {config.database_config.host}:{config.database_config.port}/{config.database_config.database}")
    
    # è®¾ç½®æµ‹è¯•æ•°æ®
    if not setup_mysql_test_data():
        logger.error("æµ‹è¯•æ•°æ®è®¾ç½®å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
        return
    
    try:
        # 1. ç®€å•æŸ¥è¯¢æµ‹è¯•
        logger.info("\n" + "="*60)
        simple_result = test_simple_query()
        
        # 2. å¤æ‚æŸ¥è¯¢æµ‹è¯•
        logger.info("\n" + "="*60)
        complex_result = test_complex_query()
        
        # 3. èšåˆæŸ¥è¯¢æµ‹è¯•
        logger.info("\n" + "="*60)
        agg_result = test_aggregation_query()
        
        # 4. é”™è¯¯å¤„ç†æµ‹è¯•
        logger.info("\n" + "="*60)
        error_result = test_error_handling()
        
        # 5. ç»Ÿè®¡åŠŸèƒ½æµ‹è¯•
        logger.info("\n" + "="*60)
        batch_results, stats = test_workflow_statistics()
        
        # 6. å¹¶å‘æŸ¥è¯¢æµ‹è¯•
        logger.info("\n" + "="*60)
        concurrent_results = test_concurrent_queries()
        
        # æ€»ç»“
        logger.info("\n" + "="*60)
        logger.info("å®Œæ•´å·¥ä½œæµæµ‹è¯•æ€»ç»“:")
        
        test_results = [
            ("ç®€å•æŸ¥è¯¢", simple_result['success']),
            ("å¤æ‚æŸ¥è¯¢", complex_result['success']),
            ("èšåˆæŸ¥è¯¢", agg_result['success']),
            ("é”™è¯¯å¤„ç†", not error_result['success']),  # é”™è¯¯å¤„ç†æµ‹è¯•æœŸæœ›å¤±è´¥
            ("æ‰¹é‡ç»Ÿè®¡", len(batch_results) > 0),
            ("å¹¶å‘å¤„ç†", len(concurrent_results) > 0)
        ]
        
        for test_name, success in test_results:
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            logger.info(f"  {test_name}: {status}")
        
        total_passed = sum(1 for _, success in test_results if success)
        logger.info(f"\næµ‹è¯•é€šè¿‡ç‡: {total_passed}/{len(test_results)} ({total_passed/len(test_results)*100:.1f}%)")
        
        if total_passed == len(test_results):
            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å·¥ä½œæµç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼")
        else:
            logger.warning("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        logger.info("\n" + "="*60)
        logger.info("æœ€ç»ˆç³»ç»Ÿç»Ÿè®¡:")
        logger.info(f"  æ•°æ®åº“: MySQL {config.database_config.database}")
        logger.info(f"  æ€»æŸ¥è¯¢å¤„ç†: {stats['total_queries'] if 'stats' in locals() else 0}")
        logger.info(f"  å·¥ä½œæµæ¡†æ¶: LangGraph")
        logger.info(f"  æ™ºèƒ½ä½“åä½œ: Selector + Decomposer + Refiner")
        
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†æµ‹è¯•æ•°æ®
        cleanup_mysql_test_data()


if __name__ == "__main__":
    main()